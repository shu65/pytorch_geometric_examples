{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch Geometric Variational Graph AutoEncoder ",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP8JZfHo3KPnq7VejaNRjSt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shu65/pytorch_geometric_examples/blob/main/PyTorch_Geometric_Variational_Graph_AutoEncoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.11.0+cu113.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doQKbBK_D9f6",
        "outputId": "7c88f5aa-49ce-4fbf-c2e0-700d26ef7f18"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-1.11.0+cu113.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-1.11.0%2Bcu113/torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl (7.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.9 MB 2.8 MB/s \n",
            "\u001b[?25hCollecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-1.11.0%2Bcu113/torch_sparse-0.6.13-cp37-cp37m-linux_x86_64.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 46.8 MB/s \n",
            "\u001b[?25hCollecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-1.11.0%2Bcu113/torch_cluster-1.6.0-cp37-cp37m-linux_x86_64.whl (2.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 56.7 MB/s \n",
            "\u001b[?25hCollecting torch-spline-conv\n",
            "  Downloading https://data.pyg.org/whl/torch-1.11.0%2Bcu113/torch_spline_conv-1.2.1-cp37-cp37m-linux_x86_64.whl (750 kB)\n",
            "\u001b[K     |████████████████████████████████| 750 kB 57.9 MB/s \n",
            "\u001b[?25hCollecting torch-geometric\n",
            "  Downloading torch_geometric-2.0.4.tar.gz (407 kB)\n",
            "\u001b[K     |████████████████████████████████| 407 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.21.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.10.8)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.0.4-py3-none-any.whl size=616603 sha256=8893261acbbd8c06851a58f8d4e4a7fdfeb6c195da510ec143ed9e07ea08e96d\n",
            "  Stored in directory: /root/.cache/pip/wheels/18/a6/a4/ca18c3051fcead866fe7b85700ee2240d883562a1bc70ce421\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-spline-conv, torch-sparse, torch-scatter, torch-geometric, torch-cluster\n",
            "Successfully installed torch-cluster-1.6.0 torch-geometric-2.0.4 torch-scatter-2.0.9 torch-sparse-0.6.13 torch-spline-conv-1.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbQGpqvYDvxC",
        "outputId": "106dc9c5-15a4-43f1-f10d-c8d729f0453f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch                         1.11.0+cu113\n",
            "torch-cluster                 1.6.0\n",
            "torch-geometric               2.0.4\n",
            "torch-scatter                 2.0.9\n",
            "torch-sparse                  0.6.13\n",
            "torch-spline-conv             1.2.1\n",
            "torchaudio                    0.11.0+cu113\n",
            "torchsummary                  1.5.1\n",
            "torchtext                     0.12.0\n",
            "torchvision                   0.12.0+cu113\n"
          ]
        }
      ],
      "source": [
        "!pip list | grep torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import os\n",
        "\n",
        "import torch\n",
        "\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.nn import VGAE, GCNConv\n",
        "\n",
        "device = 'cpu'\n",
        "transform = T.Compose([\n",
        "    T.NormalizeFeatures(),\n",
        "    T.ToDevice(device),\n",
        "    T.RandomLinkSplit(num_val=0.05, num_test=0.1, is_undirected=True,\n",
        "                      split_labels=True, add_negative_train_samples=False),\n",
        "])\n",
        "path = os.path.join(\"tmp\", \"data\", \"Planetoid\")\n",
        "dataset = Planetoid(path, \"PubMed\", transform=transform)\n",
        "train_data, val_data, test_data = dataset[0]\n",
        "train_data, val_data, test_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwX2T-9_Ey4_",
        "outputId": "a3b70102-3b22-4966-f565-c59967b1f1cf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.test.index\n",
            "Processing...\n",
            "Done!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Data(x=[19717, 500], edge_index=[2, 75352], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], pos_edge_label=[37676], pos_edge_label_index=[2, 37676]),\n",
              " Data(x=[19717, 500], edge_index=[2, 75352], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], pos_edge_label=[2216], pos_edge_label_index=[2, 2216], neg_edge_label=[2216], neg_edge_label_index=[2, 2216]),\n",
              " Data(x=[19717, 500], edge_index=[2, 79784], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], pos_edge_label=[4432], pos_edge_label_index=[2, 4432], neg_edge_label=[4432], neg_edge_label_index=[2, 4432]))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUzFpYbLBI5A",
        "outputId": "5be581d2-2d49-43d5-ab77-324638c6bb8c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [0.0554, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        ...,\n",
              "        [0.0000, 0.0114, 0.0047,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [0.0531, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0145, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WzqSFz6BT5G",
        "outputId": "bec29909-1de4-474b-a94e-dbbada34d57e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 1, 0,  ..., 2, 0, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class VariationalGCNEncoder(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, 2 * out_channels)\n",
        "        self.conv_mu = GCNConv(2 * out_channels, out_channels)\n",
        "        self.conv_logstd = GCNConv(2 * out_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index).relu()\n",
        "        return self.conv_mu(x, edge_index), self.conv_logstd(x, edge_index)\n",
        "\n",
        "\n",
        "in_channels = dataset.num_features\n",
        "out_channels = 16\n",
        "model = VGAE(VariationalGCNEncoder(in_channels, out_channels))\n",
        "model.encoder, model.decoder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bw3DXF6NFCg9",
        "outputId": "1e37552f-852f-4bc8-92a0-62f11c4275bc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(VariationalGCNEncoder(\n",
              "   (conv1): GCNConv(500, 32)\n",
              "   (conv_mu): GCNConv(32, 16)\n",
              "   (conv_logstd): GCNConv(32, 16)\n",
              " ), InnerProductDecoder())"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(0, 400):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    z = model.encode(train_data.x, train_data.edge_index)\n",
        "    recon_loss = model.recon_loss(z, train_data.pos_edge_label_index)\n",
        "    kl_loss = (1 / train_data.num_nodes) * model.kl_loss()\n",
        "    loss = recon_loss + kl_loss\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    model.eval()\n",
        "    z = model.encode(test_data.x, test_data.edge_index)\n",
        "    auc, ap = model.test(z, test_data.pos_edge_label_index, test_data.neg_edge_label_index)\n",
        "\n",
        "    print(f'Epoch: {epoch:03d}, AUC: {auc:.4f}, AP: {ap:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28GboL0ISvbE",
        "outputId": "5392a908-9de4-4ad8-ce27-2e48da586ea5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 000, AUC: 0.8592, AP: 0.8450\n",
            "Epoch: 001, AUC: 0.8783, AP: 0.8559\n",
            "Epoch: 002, AUC: 0.8833, AP: 0.8590\n",
            "Epoch: 003, AUC: 0.8854, AP: 0.8605\n",
            "Epoch: 004, AUC: 0.8866, AP: 0.8613\n",
            "Epoch: 005, AUC: 0.8873, AP: 0.8618\n",
            "Epoch: 006, AUC: 0.8879, AP: 0.8623\n",
            "Epoch: 007, AUC: 0.8883, AP: 0.8626\n",
            "Epoch: 008, AUC: 0.8887, AP: 0.8629\n",
            "Epoch: 009, AUC: 0.8890, AP: 0.8633\n",
            "Epoch: 010, AUC: 0.8893, AP: 0.8636\n",
            "Epoch: 011, AUC: 0.8897, AP: 0.8640\n",
            "Epoch: 012, AUC: 0.8900, AP: 0.8643\n",
            "Epoch: 013, AUC: 0.8903, AP: 0.8646\n",
            "Epoch: 014, AUC: 0.8904, AP: 0.8649\n",
            "Epoch: 015, AUC: 0.8904, AP: 0.8650\n",
            "Epoch: 016, AUC: 0.8901, AP: 0.8650\n",
            "Epoch: 017, AUC: 0.8897, AP: 0.8648\n",
            "Epoch: 018, AUC: 0.8894, AP: 0.8647\n",
            "Epoch: 019, AUC: 0.8896, AP: 0.8648\n",
            "Epoch: 020, AUC: 0.8901, AP: 0.8651\n",
            "Epoch: 021, AUC: 0.8906, AP: 0.8654\n",
            "Epoch: 022, AUC: 0.8909, AP: 0.8656\n",
            "Epoch: 023, AUC: 0.8911, AP: 0.8658\n",
            "Epoch: 024, AUC: 0.8912, AP: 0.8659\n",
            "Epoch: 025, AUC: 0.8911, AP: 0.8659\n",
            "Epoch: 026, AUC: 0.8909, AP: 0.8659\n",
            "Epoch: 027, AUC: 0.8906, AP: 0.8658\n",
            "Epoch: 028, AUC: 0.8905, AP: 0.8659\n",
            "Epoch: 029, AUC: 0.8908, AP: 0.8661\n",
            "Epoch: 030, AUC: 0.8913, AP: 0.8664\n",
            "Epoch: 031, AUC: 0.8917, AP: 0.8667\n",
            "Epoch: 032, AUC: 0.8918, AP: 0.8668\n",
            "Epoch: 033, AUC: 0.8918, AP: 0.8668\n",
            "Epoch: 034, AUC: 0.8915, AP: 0.8667\n",
            "Epoch: 035, AUC: 0.8911, AP: 0.8666\n",
            "Epoch: 036, AUC: 0.8909, AP: 0.8665\n",
            "Epoch: 037, AUC: 0.8911, AP: 0.8668\n",
            "Epoch: 038, AUC: 0.8916, AP: 0.8671\n",
            "Epoch: 039, AUC: 0.8920, AP: 0.8673\n",
            "Epoch: 040, AUC: 0.8921, AP: 0.8675\n",
            "Epoch: 041, AUC: 0.8919, AP: 0.8675\n",
            "Epoch: 042, AUC: 0.8915, AP: 0.8674\n",
            "Epoch: 043, AUC: 0.8914, AP: 0.8674\n",
            "Epoch: 044, AUC: 0.8915, AP: 0.8676\n",
            "Epoch: 045, AUC: 0.8919, AP: 0.8679\n",
            "Epoch: 046, AUC: 0.8923, AP: 0.8682\n",
            "Epoch: 047, AUC: 0.8925, AP: 0.8684\n",
            "Epoch: 048, AUC: 0.8922, AP: 0.8683\n",
            "Epoch: 049, AUC: 0.8919, AP: 0.8683\n",
            "Epoch: 050, AUC: 0.8918, AP: 0.8683\n",
            "Epoch: 051, AUC: 0.8921, AP: 0.8686\n",
            "Epoch: 052, AUC: 0.8925, AP: 0.8689\n",
            "Epoch: 053, AUC: 0.8927, AP: 0.8691\n",
            "Epoch: 054, AUC: 0.8926, AP: 0.8692\n",
            "Epoch: 055, AUC: 0.8925, AP: 0.8692\n",
            "Epoch: 056, AUC: 0.8925, AP: 0.8693\n",
            "Epoch: 057, AUC: 0.8927, AP: 0.8696\n",
            "Epoch: 058, AUC: 0.8931, AP: 0.8699\n",
            "Epoch: 059, AUC: 0.8934, AP: 0.8702\n",
            "Epoch: 060, AUC: 0.8933, AP: 0.8703\n",
            "Epoch: 061, AUC: 0.8930, AP: 0.8703\n",
            "Epoch: 062, AUC: 0.8931, AP: 0.8704\n",
            "Epoch: 063, AUC: 0.8933, AP: 0.8707\n",
            "Epoch: 064, AUC: 0.8936, AP: 0.8710\n",
            "Epoch: 065, AUC: 0.8937, AP: 0.8712\n",
            "Epoch: 066, AUC: 0.8937, AP: 0.8714\n",
            "Epoch: 067, AUC: 0.8938, AP: 0.8715\n",
            "Epoch: 068, AUC: 0.8940, AP: 0.8718\n",
            "Epoch: 069, AUC: 0.8940, AP: 0.8719\n",
            "Epoch: 070, AUC: 0.8941, AP: 0.8721\n",
            "Epoch: 071, AUC: 0.8943, AP: 0.8724\n",
            "Epoch: 072, AUC: 0.8944, AP: 0.8726\n",
            "Epoch: 073, AUC: 0.8945, AP: 0.8728\n",
            "Epoch: 074, AUC: 0.8946, AP: 0.8730\n",
            "Epoch: 075, AUC: 0.8947, AP: 0.8732\n",
            "Epoch: 076, AUC: 0.8946, AP: 0.8733\n",
            "Epoch: 077, AUC: 0.8945, AP: 0.8735\n",
            "Epoch: 078, AUC: 0.8944, AP: 0.8736\n",
            "Epoch: 079, AUC: 0.8944, AP: 0.8738\n",
            "Epoch: 080, AUC: 0.8946, AP: 0.8741\n",
            "Epoch: 081, AUC: 0.8945, AP: 0.8743\n",
            "Epoch: 082, AUC: 0.8945, AP: 0.8744\n",
            "Epoch: 083, AUC: 0.8944, AP: 0.8746\n",
            "Epoch: 084, AUC: 0.8941, AP: 0.8746\n",
            "Epoch: 085, AUC: 0.8940, AP: 0.8748\n",
            "Epoch: 086, AUC: 0.8940, AP: 0.8749\n",
            "Epoch: 087, AUC: 0.8939, AP: 0.8751\n",
            "Epoch: 088, AUC: 0.8938, AP: 0.8752\n",
            "Epoch: 089, AUC: 0.8936, AP: 0.8753\n",
            "Epoch: 090, AUC: 0.8931, AP: 0.8753\n",
            "Epoch: 091, AUC: 0.8930, AP: 0.8754\n",
            "Epoch: 092, AUC: 0.8928, AP: 0.8755\n",
            "Epoch: 093, AUC: 0.8929, AP: 0.8758\n",
            "Epoch: 094, AUC: 0.8926, AP: 0.8759\n",
            "Epoch: 095, AUC: 0.8923, AP: 0.8759\n",
            "Epoch: 096, AUC: 0.8915, AP: 0.8758\n",
            "Epoch: 097, AUC: 0.8911, AP: 0.8759\n",
            "Epoch: 098, AUC: 0.8915, AP: 0.8763\n",
            "Epoch: 099, AUC: 0.8921, AP: 0.8767\n",
            "Epoch: 100, AUC: 0.8924, AP: 0.8771\n",
            "Epoch: 101, AUC: 0.8919, AP: 0.8772\n",
            "Epoch: 102, AUC: 0.8912, AP: 0.8772\n",
            "Epoch: 103, AUC: 0.8915, AP: 0.8776\n",
            "Epoch: 104, AUC: 0.8923, AP: 0.8782\n",
            "Epoch: 105, AUC: 0.8926, AP: 0.8786\n",
            "Epoch: 106, AUC: 0.8918, AP: 0.8786\n",
            "Epoch: 107, AUC: 0.8916, AP: 0.8789\n",
            "Epoch: 108, AUC: 0.8932, AP: 0.8800\n",
            "Epoch: 109, AUC: 0.8956, AP: 0.8815\n",
            "Epoch: 110, AUC: 0.8975, AP: 0.8829\n",
            "Epoch: 111, AUC: 0.8983, AP: 0.8839\n",
            "Epoch: 112, AUC: 0.8992, AP: 0.8851\n",
            "Epoch: 113, AUC: 0.9011, AP: 0.8868\n",
            "Epoch: 114, AUC: 0.9041, AP: 0.8889\n",
            "Epoch: 115, AUC: 0.9067, AP: 0.8909\n",
            "Epoch: 116, AUC: 0.9086, AP: 0.8928\n",
            "Epoch: 117, AUC: 0.9100, AP: 0.8946\n",
            "Epoch: 118, AUC: 0.9114, AP: 0.8964\n",
            "Epoch: 119, AUC: 0.9133, AP: 0.8985\n",
            "Epoch: 120, AUC: 0.9159, AP: 0.9009\n",
            "Epoch: 121, AUC: 0.9180, AP: 0.9031\n",
            "Epoch: 122, AUC: 0.9185, AP: 0.9047\n",
            "Epoch: 123, AUC: 0.9180, AP: 0.9056\n",
            "Epoch: 124, AUC: 0.9172, AP: 0.9060\n",
            "Epoch: 125, AUC: 0.9165, AP: 0.9062\n",
            "Epoch: 126, AUC: 0.9158, AP: 0.9062\n",
            "Epoch: 127, AUC: 0.9142, AP: 0.9054\n",
            "Epoch: 128, AUC: 0.9109, AP: 0.9032\n",
            "Epoch: 129, AUC: 0.9057, AP: 0.8993\n",
            "Epoch: 130, AUC: 0.8997, AP: 0.8948\n",
            "Epoch: 131, AUC: 0.8958, AP: 0.8916\n",
            "Epoch: 132, AUC: 0.8924, AP: 0.8888\n",
            "Epoch: 133, AUC: 0.8896, AP: 0.8862\n",
            "Epoch: 134, AUC: 0.8866, AP: 0.8837\n",
            "Epoch: 135, AUC: 0.8825, AP: 0.8806\n",
            "Epoch: 136, AUC: 0.8790, AP: 0.8779\n",
            "Epoch: 137, AUC: 0.8770, AP: 0.8763\n",
            "Epoch: 138, AUC: 0.8765, AP: 0.8761\n",
            "Epoch: 139, AUC: 0.8769, AP: 0.8764\n",
            "Epoch: 140, AUC: 0.8778, AP: 0.8772\n",
            "Epoch: 141, AUC: 0.8789, AP: 0.8781\n",
            "Epoch: 142, AUC: 0.8809, AP: 0.8797\n",
            "Epoch: 143, AUC: 0.8825, AP: 0.8812\n",
            "Epoch: 144, AUC: 0.8835, AP: 0.8823\n",
            "Epoch: 145, AUC: 0.8842, AP: 0.8830\n",
            "Epoch: 146, AUC: 0.8861, AP: 0.8844\n",
            "Epoch: 147, AUC: 0.8891, AP: 0.8868\n",
            "Epoch: 148, AUC: 0.8916, AP: 0.8889\n",
            "Epoch: 149, AUC: 0.8932, AP: 0.8902\n",
            "Epoch: 150, AUC: 0.8944, AP: 0.8910\n",
            "Epoch: 151, AUC: 0.8959, AP: 0.8922\n",
            "Epoch: 152, AUC: 0.8973, AP: 0.8933\n",
            "Epoch: 153, AUC: 0.8981, AP: 0.8941\n",
            "Epoch: 154, AUC: 0.8983, AP: 0.8942\n",
            "Epoch: 155, AUC: 0.8985, AP: 0.8944\n",
            "Epoch: 156, AUC: 0.8989, AP: 0.8948\n",
            "Epoch: 157, AUC: 0.8990, AP: 0.8950\n",
            "Epoch: 158, AUC: 0.8983, AP: 0.8946\n",
            "Epoch: 159, AUC: 0.8962, AP: 0.8932\n",
            "Epoch: 160, AUC: 0.8946, AP: 0.8921\n",
            "Epoch: 161, AUC: 0.8935, AP: 0.8916\n",
            "Epoch: 162, AUC: 0.8939, AP: 0.8919\n",
            "Epoch: 163, AUC: 0.8945, AP: 0.8922\n",
            "Epoch: 164, AUC: 0.8942, AP: 0.8921\n",
            "Epoch: 165, AUC: 0.8927, AP: 0.8913\n",
            "Epoch: 166, AUC: 0.8910, AP: 0.8902\n",
            "Epoch: 167, AUC: 0.8901, AP: 0.8896\n",
            "Epoch: 168, AUC: 0.8901, AP: 0.8897\n",
            "Epoch: 169, AUC: 0.8916, AP: 0.8909\n",
            "Epoch: 170, AUC: 0.8927, AP: 0.8918\n",
            "Epoch: 171, AUC: 0.8932, AP: 0.8923\n",
            "Epoch: 172, AUC: 0.8931, AP: 0.8922\n",
            "Epoch: 173, AUC: 0.8931, AP: 0.8924\n",
            "Epoch: 174, AUC: 0.8932, AP: 0.8928\n",
            "Epoch: 175, AUC: 0.8942, AP: 0.8936\n",
            "Epoch: 176, AUC: 0.8953, AP: 0.8944\n",
            "Epoch: 177, AUC: 0.8968, AP: 0.8956\n",
            "Epoch: 178, AUC: 0.8980, AP: 0.8968\n",
            "Epoch: 179, AUC: 0.8984, AP: 0.8972\n",
            "Epoch: 180, AUC: 0.8980, AP: 0.8971\n",
            "Epoch: 181, AUC: 0.8985, AP: 0.8975\n",
            "Epoch: 182, AUC: 0.8996, AP: 0.8987\n",
            "Epoch: 183, AUC: 0.9007, AP: 0.8998\n",
            "Epoch: 184, AUC: 0.9012, AP: 0.9002\n",
            "Epoch: 185, AUC: 0.9008, AP: 0.8999\n",
            "Epoch: 186, AUC: 0.9010, AP: 0.9005\n",
            "Epoch: 187, AUC: 0.9019, AP: 0.9015\n",
            "Epoch: 188, AUC: 0.9023, AP: 0.9020\n",
            "Epoch: 189, AUC: 0.9028, AP: 0.9023\n",
            "Epoch: 190, AUC: 0.9041, AP: 0.9036\n",
            "Epoch: 191, AUC: 0.9049, AP: 0.9047\n",
            "Epoch: 192, AUC: 0.9055, AP: 0.9054\n",
            "Epoch: 193, AUC: 0.9062, AP: 0.9062\n",
            "Epoch: 194, AUC: 0.9068, AP: 0.9067\n",
            "Epoch: 195, AUC: 0.9078, AP: 0.9079\n",
            "Epoch: 196, AUC: 0.9086, AP: 0.9090\n",
            "Epoch: 197, AUC: 0.9095, AP: 0.9099\n",
            "Epoch: 198, AUC: 0.9104, AP: 0.9107\n",
            "Epoch: 199, AUC: 0.9116, AP: 0.9120\n",
            "Epoch: 200, AUC: 0.9128, AP: 0.9133\n",
            "Epoch: 201, AUC: 0.9136, AP: 0.9141\n",
            "Epoch: 202, AUC: 0.9139, AP: 0.9144\n",
            "Epoch: 203, AUC: 0.9143, AP: 0.9147\n",
            "Epoch: 204, AUC: 0.9153, AP: 0.9159\n",
            "Epoch: 205, AUC: 0.9160, AP: 0.9165\n",
            "Epoch: 206, AUC: 0.9163, AP: 0.9168\n",
            "Epoch: 207, AUC: 0.9160, AP: 0.9167\n",
            "Epoch: 208, AUC: 0.9164, AP: 0.9170\n",
            "Epoch: 209, AUC: 0.9159, AP: 0.9165\n",
            "Epoch: 210, AUC: 0.9156, AP: 0.9163\n",
            "Epoch: 211, AUC: 0.9155, AP: 0.9164\n",
            "Epoch: 212, AUC: 0.9155, AP: 0.9164\n",
            "Epoch: 213, AUC: 0.9157, AP: 0.9163\n",
            "Epoch: 214, AUC: 0.9154, AP: 0.9160\n",
            "Epoch: 215, AUC: 0.9154, AP: 0.9163\n",
            "Epoch: 216, AUC: 0.9161, AP: 0.9170\n",
            "Epoch: 217, AUC: 0.9164, AP: 0.9173\n",
            "Epoch: 218, AUC: 0.9164, AP: 0.9173\n",
            "Epoch: 219, AUC: 0.9167, AP: 0.9178\n",
            "Epoch: 220, AUC: 0.9171, AP: 0.9184\n",
            "Epoch: 221, AUC: 0.9181, AP: 0.9193\n",
            "Epoch: 222, AUC: 0.9187, AP: 0.9199\n",
            "Epoch: 223, AUC: 0.9184, AP: 0.9199\n",
            "Epoch: 224, AUC: 0.9185, AP: 0.9201\n",
            "Epoch: 225, AUC: 0.9192, AP: 0.9208\n",
            "Epoch: 226, AUC: 0.9201, AP: 0.9216\n",
            "Epoch: 227, AUC: 0.9200, AP: 0.9217\n",
            "Epoch: 228, AUC: 0.9198, AP: 0.9215\n",
            "Epoch: 229, AUC: 0.9208, AP: 0.9225\n",
            "Epoch: 230, AUC: 0.9213, AP: 0.9230\n",
            "Epoch: 231, AUC: 0.9202, AP: 0.9221\n",
            "Epoch: 232, AUC: 0.9200, AP: 0.9219\n",
            "Epoch: 233, AUC: 0.9211, AP: 0.9231\n",
            "Epoch: 234, AUC: 0.9219, AP: 0.9238\n",
            "Epoch: 235, AUC: 0.9212, AP: 0.9232\n",
            "Epoch: 236, AUC: 0.9207, AP: 0.9227\n",
            "Epoch: 237, AUC: 0.9211, AP: 0.9231\n",
            "Epoch: 238, AUC: 0.9227, AP: 0.9246\n",
            "Epoch: 239, AUC: 0.9227, AP: 0.9247\n",
            "Epoch: 240, AUC: 0.9212, AP: 0.9234\n",
            "Epoch: 241, AUC: 0.9210, AP: 0.9233\n",
            "Epoch: 242, AUC: 0.9224, AP: 0.9246\n",
            "Epoch: 243, AUC: 0.9233, AP: 0.9254\n",
            "Epoch: 244, AUC: 0.9224, AP: 0.9245\n",
            "Epoch: 245, AUC: 0.9217, AP: 0.9239\n",
            "Epoch: 246, AUC: 0.9225, AP: 0.9248\n",
            "Epoch: 247, AUC: 0.9237, AP: 0.9258\n",
            "Epoch: 248, AUC: 0.9234, AP: 0.9256\n",
            "Epoch: 249, AUC: 0.9227, AP: 0.9249\n",
            "Epoch: 250, AUC: 0.9226, AP: 0.9248\n",
            "Epoch: 251, AUC: 0.9238, AP: 0.9260\n",
            "Epoch: 252, AUC: 0.9246, AP: 0.9266\n",
            "Epoch: 253, AUC: 0.9237, AP: 0.9259\n",
            "Epoch: 254, AUC: 0.9235, AP: 0.9257\n",
            "Epoch: 255, AUC: 0.9246, AP: 0.9267\n",
            "Epoch: 256, AUC: 0.9250, AP: 0.9271\n",
            "Epoch: 257, AUC: 0.9245, AP: 0.9267\n",
            "Epoch: 258, AUC: 0.9246, AP: 0.9267\n",
            "Epoch: 259, AUC: 0.9254, AP: 0.9274\n",
            "Epoch: 260, AUC: 0.9256, AP: 0.9278\n",
            "Epoch: 261, AUC: 0.9256, AP: 0.9277\n",
            "Epoch: 262, AUC: 0.9260, AP: 0.9280\n",
            "Epoch: 263, AUC: 0.9265, AP: 0.9284\n",
            "Epoch: 264, AUC: 0.9269, AP: 0.9289\n",
            "Epoch: 265, AUC: 0.9268, AP: 0.9289\n",
            "Epoch: 266, AUC: 0.9269, AP: 0.9290\n",
            "Epoch: 267, AUC: 0.9273, AP: 0.9293\n",
            "Epoch: 268, AUC: 0.9277, AP: 0.9297\n",
            "Epoch: 269, AUC: 0.9283, AP: 0.9302\n",
            "Epoch: 270, AUC: 0.9284, AP: 0.9303\n",
            "Epoch: 271, AUC: 0.9282, AP: 0.9301\n",
            "Epoch: 272, AUC: 0.9287, AP: 0.9307\n",
            "Epoch: 273, AUC: 0.9298, AP: 0.9316\n",
            "Epoch: 274, AUC: 0.9299, AP: 0.9316\n",
            "Epoch: 275, AUC: 0.9295, AP: 0.9313\n",
            "Epoch: 276, AUC: 0.9306, AP: 0.9324\n",
            "Epoch: 277, AUC: 0.9314, AP: 0.9330\n",
            "Epoch: 278, AUC: 0.9314, AP: 0.9330\n",
            "Epoch: 279, AUC: 0.9313, AP: 0.9330\n",
            "Epoch: 280, AUC: 0.9322, AP: 0.9339\n",
            "Epoch: 281, AUC: 0.9328, AP: 0.9345\n",
            "Epoch: 282, AUC: 0.9327, AP: 0.9344\n",
            "Epoch: 283, AUC: 0.9334, AP: 0.9350\n",
            "Epoch: 284, AUC: 0.9344, AP: 0.9359\n",
            "Epoch: 285, AUC: 0.9346, AP: 0.9363\n",
            "Epoch: 286, AUC: 0.9347, AP: 0.9364\n",
            "Epoch: 287, AUC: 0.9354, AP: 0.9371\n",
            "Epoch: 288, AUC: 0.9359, AP: 0.9375\n",
            "Epoch: 289, AUC: 0.9366, AP: 0.9383\n",
            "Epoch: 290, AUC: 0.9374, AP: 0.9390\n",
            "Epoch: 291, AUC: 0.9376, AP: 0.9393\n",
            "Epoch: 292, AUC: 0.9377, AP: 0.9395\n",
            "Epoch: 293, AUC: 0.9381, AP: 0.9399\n",
            "Epoch: 294, AUC: 0.9389, AP: 0.9407\n",
            "Epoch: 295, AUC: 0.9397, AP: 0.9415\n",
            "Epoch: 296, AUC: 0.9397, AP: 0.9416\n",
            "Epoch: 297, AUC: 0.9396, AP: 0.9416\n",
            "Epoch: 298, AUC: 0.9403, AP: 0.9423\n",
            "Epoch: 299, AUC: 0.9411, AP: 0.9431\n",
            "Epoch: 300, AUC: 0.9411, AP: 0.9431\n",
            "Epoch: 301, AUC: 0.9410, AP: 0.9431\n",
            "Epoch: 302, AUC: 0.9415, AP: 0.9437\n",
            "Epoch: 303, AUC: 0.9420, AP: 0.9440\n",
            "Epoch: 304, AUC: 0.9419, AP: 0.9439\n",
            "Epoch: 305, AUC: 0.9417, AP: 0.9439\n",
            "Epoch: 306, AUC: 0.9423, AP: 0.9444\n",
            "Epoch: 307, AUC: 0.9424, AP: 0.9445\n",
            "Epoch: 308, AUC: 0.9421, AP: 0.9442\n",
            "Epoch: 309, AUC: 0.9426, AP: 0.9446\n",
            "Epoch: 310, AUC: 0.9425, AP: 0.9446\n",
            "Epoch: 311, AUC: 0.9423, AP: 0.9444\n",
            "Epoch: 312, AUC: 0.9427, AP: 0.9448\n",
            "Epoch: 313, AUC: 0.9429, AP: 0.9448\n",
            "Epoch: 314, AUC: 0.9432, AP: 0.9451\n",
            "Epoch: 315, AUC: 0.9427, AP: 0.9448\n",
            "Epoch: 316, AUC: 0.9427, AP: 0.9447\n",
            "Epoch: 317, AUC: 0.9431, AP: 0.9450\n",
            "Epoch: 318, AUC: 0.9435, AP: 0.9453\n",
            "Epoch: 319, AUC: 0.9430, AP: 0.9451\n",
            "Epoch: 320, AUC: 0.9426, AP: 0.9447\n",
            "Epoch: 321, AUC: 0.9435, AP: 0.9454\n",
            "Epoch: 322, AUC: 0.9439, AP: 0.9457\n",
            "Epoch: 323, AUC: 0.9429, AP: 0.9450\n",
            "Epoch: 324, AUC: 0.9428, AP: 0.9449\n",
            "Epoch: 325, AUC: 0.9437, AP: 0.9456\n",
            "Epoch: 326, AUC: 0.9443, AP: 0.9460\n",
            "Epoch: 327, AUC: 0.9435, AP: 0.9455\n",
            "Epoch: 328, AUC: 0.9429, AP: 0.9451\n",
            "Epoch: 329, AUC: 0.9435, AP: 0.9455\n",
            "Epoch: 330, AUC: 0.9443, AP: 0.9460\n",
            "Epoch: 331, AUC: 0.9441, AP: 0.9460\n",
            "Epoch: 332, AUC: 0.9435, AP: 0.9456\n",
            "Epoch: 333, AUC: 0.9433, AP: 0.9454\n",
            "Epoch: 334, AUC: 0.9442, AP: 0.9462\n",
            "Epoch: 335, AUC: 0.9442, AP: 0.9461\n",
            "Epoch: 336, AUC: 0.9435, AP: 0.9456\n",
            "Epoch: 337, AUC: 0.9437, AP: 0.9458\n",
            "Epoch: 338, AUC: 0.9443, AP: 0.9463\n",
            "Epoch: 339, AUC: 0.9443, AP: 0.9462\n",
            "Epoch: 340, AUC: 0.9439, AP: 0.9459\n",
            "Epoch: 341, AUC: 0.9438, AP: 0.9459\n",
            "Epoch: 342, AUC: 0.9443, AP: 0.9463\n",
            "Epoch: 343, AUC: 0.9442, AP: 0.9463\n",
            "Epoch: 344, AUC: 0.9439, AP: 0.9459\n",
            "Epoch: 345, AUC: 0.9442, AP: 0.9462\n",
            "Epoch: 346, AUC: 0.9446, AP: 0.9465\n",
            "Epoch: 347, AUC: 0.9442, AP: 0.9462\n",
            "Epoch: 348, AUC: 0.9441, AP: 0.9461\n",
            "Epoch: 349, AUC: 0.9443, AP: 0.9463\n",
            "Epoch: 350, AUC: 0.9445, AP: 0.9464\n",
            "Epoch: 351, AUC: 0.9444, AP: 0.9463\n",
            "Epoch: 352, AUC: 0.9443, AP: 0.9463\n",
            "Epoch: 353, AUC: 0.9444, AP: 0.9463\n",
            "Epoch: 354, AUC: 0.9445, AP: 0.9464\n",
            "Epoch: 355, AUC: 0.9445, AP: 0.9465\n",
            "Epoch: 356, AUC: 0.9446, AP: 0.9465\n",
            "Epoch: 357, AUC: 0.9444, AP: 0.9463\n",
            "Epoch: 358, AUC: 0.9441, AP: 0.9461\n",
            "Epoch: 359, AUC: 0.9447, AP: 0.9466\n",
            "Epoch: 360, AUC: 0.9445, AP: 0.9465\n",
            "Epoch: 361, AUC: 0.9442, AP: 0.9461\n",
            "Epoch: 362, AUC: 0.9443, AP: 0.9462\n",
            "Epoch: 363, AUC: 0.9446, AP: 0.9466\n",
            "Epoch: 364, AUC: 0.9442, AP: 0.9463\n",
            "Epoch: 365, AUC: 0.9444, AP: 0.9463\n",
            "Epoch: 366, AUC: 0.9446, AP: 0.9465\n",
            "Epoch: 367, AUC: 0.9444, AP: 0.9465\n",
            "Epoch: 368, AUC: 0.9440, AP: 0.9461\n",
            "Epoch: 369, AUC: 0.9444, AP: 0.9463\n",
            "Epoch: 370, AUC: 0.9448, AP: 0.9466\n",
            "Epoch: 371, AUC: 0.9445, AP: 0.9465\n",
            "Epoch: 372, AUC: 0.9441, AP: 0.9462\n",
            "Epoch: 373, AUC: 0.9443, AP: 0.9462\n",
            "Epoch: 374, AUC: 0.9447, AP: 0.9465\n",
            "Epoch: 375, AUC: 0.9446, AP: 0.9466\n",
            "Epoch: 376, AUC: 0.9439, AP: 0.9461\n",
            "Epoch: 377, AUC: 0.9442, AP: 0.9463\n",
            "Epoch: 378, AUC: 0.9446, AP: 0.9464\n",
            "Epoch: 379, AUC: 0.9446, AP: 0.9466\n",
            "Epoch: 380, AUC: 0.9441, AP: 0.9461\n",
            "Epoch: 381, AUC: 0.9444, AP: 0.9464\n",
            "Epoch: 382, AUC: 0.9444, AP: 0.9463\n",
            "Epoch: 383, AUC: 0.9445, AP: 0.9465\n",
            "Epoch: 384, AUC: 0.9445, AP: 0.9465\n",
            "Epoch: 385, AUC: 0.9444, AP: 0.9464\n",
            "Epoch: 386, AUC: 0.9444, AP: 0.9463\n",
            "Epoch: 387, AUC: 0.9444, AP: 0.9464\n",
            "Epoch: 388, AUC: 0.9445, AP: 0.9465\n",
            "Epoch: 389, AUC: 0.9442, AP: 0.9463\n",
            "Epoch: 390, AUC: 0.9445, AP: 0.9464\n",
            "Epoch: 391, AUC: 0.9445, AP: 0.9465\n",
            "Epoch: 392, AUC: 0.9444, AP: 0.9464\n",
            "Epoch: 393, AUC: 0.9445, AP: 0.9465\n",
            "Epoch: 394, AUC: 0.9446, AP: 0.9466\n",
            "Epoch: 395, AUC: 0.9446, AP: 0.9466\n",
            "Epoch: 396, AUC: 0.9443, AP: 0.9463\n",
            "Epoch: 397, AUC: 0.9441, AP: 0.9461\n",
            "Epoch: 398, AUC: 0.9444, AP: 0.9464\n",
            "Epoch: 399, AUC: 0.9447, AP: 0.9466\n"
          ]
        }
      ]
    }
  ]
}